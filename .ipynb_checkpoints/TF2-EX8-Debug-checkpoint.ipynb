{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200315\n",
      "<PrefetchDataset shapes: (512, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(512, 64, 64, 3) 1.0 -1.0\n",
      "0 d-loss: 0.1592302769422531 g-loss: -0.4181780219078064 gp: 0.020147614181041718\n",
      "100 d-loss: -5.740693092346191 g-loss: 0.2465856373310089 gp: 0.09691660851240158\n",
      "200 d-loss: -2.123170852661133 g-loss: -5.147572040557861 gp: 0.08859609812498093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fb559c1dc307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-fb559c1dc307>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;31m# train D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                     \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0;31m#[p.assign(tf.clip_by_value(p,-0.01, 0.01)) for p in discriminator.trainable_variables]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-fb559c1dc307>\u001b[0m in \u001b[0;36md_loss_fn\u001b[0;34m(generator, discriminator, batch_z, batch_x, is_training)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# 1. treat real image as real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;31m# 2. treat generated image as fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mfake_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0md_fake_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0md_real_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    966\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-fb559c1dc307>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    966\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_update\u001b[0;34m(self, updates, inputs)\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m             \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mvariance_update\u001b[0;34m()\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;34m\"\"\"Update self.moving_variance with the most recent data point.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_fused_avg_updates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_new_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m           return self._assign_moving_average(self.moving_variance, variance,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_assign_new_value\u001b[0;34m(self, variable, value)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AssignNewValue'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         validate_shape=validate_shape)\n\u001b[0;32m--> 228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 844\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    845\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    141\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         tld.op_callbacks, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import  os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import  numpy as np\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "\n",
    "from    PIL import Image\n",
    "import  glob\n",
    "\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# All required libs are imporeted in this cell\n",
    "import os, glob, multiprocessing\n",
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Flatten, Reshape, Conv2DTranspose, ReLU, LeakyReLU, Activation\n",
    "from tensorflow.keras import Sequential, optimizers, Input\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "z_dim = 100\n",
    "epochs = 3000000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "is_training = True\n",
    "\n",
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "\n",
    "    # @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        # img = tf.image.random_crop(img,[resize, resize])\n",
    "        # img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1 #-1~1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "\n",
    "def batch_dataset(dataset,\n",
    "                  batch_size,\n",
    "                  drop_remainder=True,\n",
    "                  n_prefetch_batch=1,\n",
    "                  filter_fn=None,\n",
    "                  map_fn=None,\n",
    "                  n_map_threads=None,\n",
    "                  filter_after_map=False,\n",
    "                  shuffle=True,\n",
    "                  shuffle_buffer_size=None,\n",
    "                  repeat=None):\n",
    "    # set defaults\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n",
    "\n",
    "    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "    else:  # [*] this is slower\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                              batch_size,\n",
    "                              drop_remainder=True,\n",
    "                              n_prefetch_batch=1,\n",
    "                              filter_fn=None,\n",
    "                              map_fn=None,\n",
    "                              n_map_threads=None,\n",
    "                              filter_after_map=False,\n",
    "                              shuffle=True,\n",
    "                              shuffle_buffer_size=None,\n",
    "                              repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                            batch_size,\n",
    "                            drop_remainder=drop_remainder,\n",
    "                            n_prefetch_batch=n_prefetch_batch,\n",
    "                            filter_fn=filter_fn,\n",
    "                            map_fn=map_fn,\n",
    "                            n_map_threads=n_map_threads,\n",
    "                            filter_after_map=filter_after_map,\n",
    "                            shuffle=shuffle,\n",
    "                            shuffle_buffer_size=shuffle_buffer_size,\n",
    "                            repeat=repeat)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else:\n",
    "        memory_data = (img_paths, labels)\n",
    "\n",
    "    def parse_fn(path, *label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # fix channels to 3\n",
    "        return (img,) + label\n",
    "\n",
    "    if map_fn:  # fuse `map_fn` and `parse_fn`\n",
    "        def map_fn_(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "\n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class Generator1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator1, self).__init__()\n",
    "        self.s = 2\n",
    "        self.k = 4\n",
    "        self.n_f = 1024\n",
    "        \n",
    "        self.dense1 = Dense(self.s * self.s * self.n_f)\n",
    "        self.reshape1 = Reshape(target_shape = (self.s, self.s, self.n_f))\n",
    "        self.conv1 = Conv2DTranspose(512, self.k, 2, 'same')\n",
    "        self.conv2 = Conv2DTranspose(256, self.k, 2, 'same')\n",
    "        self.conv3 = Conv2DTranspose(128, self.k, 2, 'same')\n",
    "        self.conv4 = Conv2DTranspose(64, self.k, 2, 'same')\n",
    "        self.conv5 = Conv2DTranspose(3, self.k, 2, 'same')\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.dense1(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.reshape1(x)\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.conv1(x))\n",
    "        x = tf.nn.leaky_relu(self.conv2(x))\n",
    "        x = tf.nn.leaky_relu(self.conv3(x))\n",
    "        x = tf.nn.leaky_relu(self.conv4(x))\n",
    "        x = tf.tanh(self.conv5(x))\n",
    "        \n",
    "        return x\n",
    "class Discriminator1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator1, self).__init__()\n",
    "        self.s = 4\n",
    "        self.k = 4\n",
    "        \n",
    "        self.conv1 = Conv2D(64, self.k, 2, 'same')\n",
    "        self.conv2 = Conv2D(128, self.k, 2, 'same')\n",
    "        self.conv3 = Conv2D(256, self.k, 2, 'same')\n",
    "        self.conv4 = Conv2D(512, self.k, 2, 'same')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(1)\n",
    "    \n",
    "    def call(self, inputs, training = None):\n",
    "        x = inputs\n",
    "        x = tf.nn.leaky_relu(self.conv1(x))\n",
    "        x = tf.nn.leaky_relu(self.conv2(x))\n",
    "        x = tf.nn.leaky_relu(self.conv3(x))\n",
    "        x = tf.nn.leaky_relu(self.conv4(x))\n",
    "        x = self.dense(self.flatten(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Generator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # z: [b, 100] => [b, 3*3*512] => [b, 3, 3, 512] => [b, 64, 64, 3]\n",
    "        self.fc = layers.Dense(3*3*512)\n",
    "\n",
    "        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = layers.Conv2DTranspose(128, 5, 2, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'valid')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [z, 100] => [z, 3*3*512]\n",
    "        x = self.fc(inputs)\n",
    "        x = tf.reshape(x, [-1, 3, 3, 512])\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        #\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = self.conv3(x)\n",
    "        x = tf.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # [b, 64, 64, 3] => [b, 1]\n",
    "        self.conv1 = layers.Conv2D(64, 5, 3, 'valid')\n",
    "\n",
    "        self.conv2 = layers.Conv2D(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = layers.Conv2D(256, 5, 3, 'valid')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "\n",
    "        # [b, h, w ,c] => [b, -1]\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = tf.nn.leaky_relu(self.conv1(inputs))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "\n",
    "        # [b, h, w, c] => [b, -1]\n",
    "        x = self.flatten(x)\n",
    "        # [b, -1] => [b, 1]\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2) \n",
    "    Image.fromarray(final_image).save(image_path)\n",
    "\n",
    "\n",
    "def celoss_ones(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    # loss = tf.keras.losses.categorical_crossentropy(y_pred=logits,\n",
    "    #                                                y_true=tf.ones_like(logits))\n",
    "    return - tf.reduce_mean(logits)\n",
    "\n",
    "\n",
    "def celoss_zeros(logits):\n",
    "    # [b, 1]\n",
    "    # [b] = [1, 1, 1, 1,]\n",
    "    # loss = tf.keras.losses.categorical_crossentropy(y_pred=logits,\n",
    "    #                                                y_true=tf.zeros_like(logits))\n",
    "    return tf.reduce_mean(logits)\n",
    "\n",
    "\n",
    "def gradient_penalty(discriminator, batch_x, fake_image):\n",
    "\n",
    "    batchsz = batch_x.shape[0]\n",
    "\n",
    "    # [b, h, w, c]\n",
    "    t = tf.random.uniform([batchsz, 1, 1, 1])\n",
    "    # [b, 1, 1, 1] => [b, h, w, c]\n",
    "    t = tf.broadcast_to(t, batch_x.shape)\n",
    "\n",
    "    interplate = t * batch_x + (1 - t) * fake_image\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([interplate])\n",
    "        d_interplote_logits = discriminator(interplate, training=True)\n",
    "    grads = tape.gradient(d_interplote_logits, interplate)\n",
    "\n",
    "    # grads:[b, h, w, c] => [b, -1]\n",
    "    grads = tf.reshape(grads, [grads.shape[0], -1])\n",
    "    gp = tf.norm(grads, axis=1) #[b]\n",
    "    gp = tf.reduce_mean( (gp-1)**2 )\n",
    "\n",
    "    return gp\n",
    "\n",
    "\n",
    "\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 1. treat real image as real\n",
    "    # 2. treat generated image as fake\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    gp = gradient_penalty(discriminator, batch_x, fake_image)\n",
    "\n",
    "    loss = d_loss_real + d_loss_fake + 10. * gp\n",
    "\n",
    "    return loss, gp\n",
    "\n",
    "\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    with tf.device('/GPU:1'):\n",
    "        tf.random.set_seed(233)\n",
    "        np.random.seed(233)\n",
    "        assert tf.__version__.startswith('2.')\n",
    "\n",
    "\n",
    "        # hyper parameters\n",
    "        z_dim = 100\n",
    "        epochs = 3000000\n",
    "        batch_size = 512\n",
    "        learning_rate = 0.0005\n",
    "        is_training = True\n",
    "\n",
    "\n",
    "        img_path = glob.glob('./faces/*.jpg')\n",
    "        assert len(img_path) > 0\n",
    "\n",
    "\n",
    "        dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)\n",
    "        print(dataset, img_shape)\n",
    "        sample = next(iter(dataset))\n",
    "        print(sample.shape, tf.reduce_max(sample).numpy(),\n",
    "              tf.reduce_min(sample).numpy())\n",
    "        dataset = dataset.repeat()\n",
    "        db_iter = iter(dataset)\n",
    "\n",
    "\n",
    "        generator = Generator() \n",
    "        generator.build(input_shape = (None, z_dim))\n",
    "        discriminator = Discriminator()\n",
    "        discriminator.build(input_shape=(None, 64, 64, 3))\n",
    "        z_sample = tf.random.normal([100, z_dim])\n",
    "\n",
    "\n",
    "        #g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "        #d_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "        g_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        d_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(5):\n",
    "                batch_z = tf.random.normal([batch_size, z_dim])\n",
    "                batch_x = next(db_iter)\n",
    "\n",
    "                # train D\n",
    "                with tf.GradientTape() as tape:\n",
    "                    d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "                #[p.assign(tf.clip_by_value(p,-0.01, 0.01)) for p in discriminator.trainable_variables]\n",
    "                grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "                d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "            batch_z = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "            grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                # for p in discriminator.trainable_variables:\n",
    "                #     print(tf.reduce_min(p).numpy(), tf.reduce_max(p).numpy())\n",
    "                print(epoch, 'd-loss:',float(d_loss), 'g-loss:', float(g_loss), 'gp:', float(gp))\n",
    "                #print(epoch, 't-d-loss:',float(t_d_loss), 't-g-loss:', float(t_g_loss), 'gp:', float(gp))\n",
    "\n",
    "                z = tf.random.normal([100, z_dim])\n",
    "                fake_image = generator(z, training=False)\n",
    "                img_path = os.path.join('gan_images', 'dc-wgan-debug-%d.png'%epoch)\n",
    "                save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
