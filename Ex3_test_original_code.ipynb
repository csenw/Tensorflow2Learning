{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (128, 32, 32, 3) (128,) tf.Tensor(-1.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 165,514\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss: 2.302992820739746\n",
      "0 100 loss: 1.9076863527297974\n",
      "0 200 loss: 1.789522409439087\n",
      "0 300 loss: 1.7752711772918701\n",
      "0 acc: 0.4372\n",
      "1 0 loss: 1.4960393905639648\n",
      "1 100 loss: 1.4095239639282227\n",
      "1 200 loss: 1.3046057224273682\n",
      "1 300 loss: 1.20320725440979\n",
      "1 acc: 0.5474\n",
      "2 0 loss: 1.2401072978973389\n",
      "2 100 loss: 1.0476899147033691\n",
      "2 200 loss: 1.2865450382232666\n",
      "2 300 loss: 1.0632706880569458\n",
      "2 acc: 0.5735\n",
      "3 0 loss: 0.9665704965591431\n",
      "3 100 loss: 1.1400383710861206\n",
      "3 200 loss: 1.0468206405639648\n",
      "3 300 loss: 0.8746795654296875\n",
      "3 acc: 0.6411\n",
      "4 0 loss: 1.0023900270462036\n",
      "4 100 loss: 0.81764817237854\n",
      "4 200 loss: 0.8420780301094055\n",
      "4 300 loss: 0.8533032536506653\n",
      "4 acc: 0.6832\n",
      "5 0 loss: 0.7566820383071899\n",
      "5 100 loss: 0.8862216472625732\n",
      "5 200 loss: 0.8040466904640198\n",
      "5 300 loss: 0.678113579750061\n",
      "5 acc: 0.7205\n",
      "6 0 loss: 0.7237188816070557\n",
      "6 100 loss: 0.727483332157135\n",
      "6 200 loss: 0.7314305901527405\n",
      "6 300 loss: 0.53626948595047\n",
      "6 acc: 0.7389\n",
      "7 0 loss: 0.4555886685848236\n",
      "7 100 loss: 0.6106262803077698\n",
      "7 200 loss: 0.4906705319881439\n",
      "7 300 loss: 0.5726811289787292\n",
      "7 acc: 0.7297\n",
      "8 0 loss: 0.5066719055175781\n",
      "8 100 loss: 0.4441468119621277\n",
      "8 200 loss: 0.40390706062316895\n",
      "8 300 loss: 0.40524905920028687\n",
      "8 acc: 0.7564\n",
      "9 0 loss: 0.4196561276912689\n",
      "9 100 loss: 0.41456127166748047\n",
      "9 200 loss: 0.38542184233665466\n",
      "9 300 loss: 0.3316076397895813\n",
      "9 acc: 0.7587\n",
      "10 0 loss: 0.32114022970199585\n",
      "10 100 loss: 0.26083824038505554\n",
      "10 200 loss: 0.2927877902984619\n",
      "10 300 loss: 0.26206353306770325\n",
      "10 acc: 0.7645\n",
      "11 0 loss: 0.21656940877437592\n",
      "11 100 loss: 0.2598523199558258\n",
      "11 200 loss: 0.23480603098869324\n",
      "11 300 loss: 0.23496875166893005\n",
      "11 acc: 0.7648\n",
      "12 0 loss: 0.2276417315006256\n",
      "12 100 loss: 0.2555709779262543\n",
      "12 200 loss: 0.16380400955677032\n",
      "12 300 loss: 0.16199639439582825\n",
      "12 acc: 0.7622\n",
      "13 0 loss: 0.20320361852645874\n",
      "13 100 loss: 0.16882839798927307\n",
      "13 200 loss: 0.1251242756843567\n",
      "13 300 loss: 0.08601951599121094\n",
      "13 acc: 0.7698\n",
      "14 0 loss: 0.06812203675508499\n",
      "14 100 loss: 0.0702643021941185\n",
      "14 200 loss: 0.13791456818580627\n",
      "14 300 loss: 0.174540713429451\n",
      "14 acc: 0.7661\n",
      "15 0 loss: 0.09120011329650879\n",
      "15 100 loss: 0.03759612515568733\n",
      "15 200 loss: 0.09722422063350677\n",
      "15 300 loss: 0.12467201799154282\n",
      "15 acc: 0.7624\n",
      "16 0 loss: 0.16073909401893616\n",
      "16 100 loss: 0.05920226871967316\n",
      "16 200 loss: 0.01487224455922842\n",
      "16 300 loss: 0.05028379708528519\n",
      "16 acc: 0.7678\n",
      "17 0 loss: 0.06339969485998154\n",
      "17 100 loss: 0.04045344889163971\n",
      "17 200 loss: 0.02615375630557537\n",
      "17 300 loss: 0.11783210188150406\n",
      "17 acc: 0.7657\n",
      "18 0 loss: 0.06474921852350235\n",
      "18 100 loss: 0.08772504329681396\n",
      "18 200 loss: 0.09198668599128723\n",
      "18 300 loss: 0.04100397229194641\n",
      "18 acc: 0.7728\n",
      "19 0 loss: 0.018810903653502464\n",
      "19 100 loss: 0.0819537490606308\n",
      "19 200 loss: 0.13777998089790344\n",
      "19 300 loss: 0.04560041427612305\n",
      "19 acc: 0.78\n",
      "20 0 loss: 0.03748473897576332\n",
      "20 100 loss: 0.04712502658367157\n",
      "20 200 loss: 0.05556422472000122\n",
      "20 300 loss: 0.023020753636956215\n",
      "20 acc: 0.7813\n",
      "21 0 loss: 0.022098299115896225\n",
      "21 100 loss: 0.014322475530207157\n",
      "21 200 loss: 0.01631166785955429\n",
      "21 300 loss: 0.045890793204307556\n",
      "21 acc: 0.7793\n",
      "22 0 loss: 0.058473944664001465\n",
      "22 100 loss: 0.05734453350305557\n",
      "22 200 loss: 0.06296306103467941\n",
      "22 300 loss: 0.11699153482913971\n",
      "22 acc: 0.7821\n",
      "23 0 loss: 0.053084809333086014\n",
      "23 100 loss: 0.059785254299640656\n",
      "23 200 loss: 0.04070676863193512\n",
      "23 300 loss: 0.04087761789560318\n",
      "23 acc: 0.7566\n",
      "24 0 loss: 0.08766959607601166\n",
      "24 100 loss: 0.02584555186331272\n",
      "24 200 loss: 0.021484483033418655\n",
      "24 300 loss: 0.029642092064023018\n",
      "24 acc: 0.7752\n",
      "25 0 loss: 0.039550866931676865\n",
      "25 100 loss: 0.03412706032395363\n",
      "25 200 loss: 0.02065960131585598\n",
      "25 300 loss: 0.01630604825913906\n",
      "25 acc: 0.7818\n",
      "26 0 loss: 0.006711435038596392\n",
      "26 100 loss: 0.014228194952011108\n",
      "26 200 loss: 0.03257841244339943\n",
      "26 300 loss: 0.002742650220170617\n",
      "26 acc: 0.7887\n",
      "27 0 loss: 0.01267421618103981\n",
      "27 100 loss: 0.023504866287112236\n",
      "27 200 loss: 0.020555445924401283\n",
      "27 300 loss: 0.00455215061083436\n",
      "27 acc: 0.7736\n",
      "28 0 loss: 0.01153026893734932\n",
      "28 100 loss: 0.04105731099843979\n",
      "28 200 loss: 0.015728037804365158\n",
      "28 300 loss: 0.15352503955364227\n",
      "28 acc: 0.7762\n",
      "29 0 loss: 0.028161076828837395\n",
      "29 100 loss: 0.0048790439032018185\n",
      "29 200 loss: 0.03012770041823387\n",
      "29 300 loss: 0.007190602365881205\n",
      "29 acc: 0.7706\n",
      "30 0 loss: 0.04460156708955765\n",
      "30 100 loss: 0.02759500965476036\n",
      "30 200 loss: 0.07710455358028412\n",
      "30 300 loss: 0.03437081724405289\n",
      "30 acc: 0.7801\n",
      "31 0 loss: 0.06271031498908997\n",
      "31 100 loss: 0.021540340036153793\n",
      "31 200 loss: 0.0165102556347847\n",
      "31 300 loss: 0.0028858636505901814\n",
      "31 acc: 0.7783\n",
      "32 0 loss: 0.02020527794957161\n",
      "32 100 loss: 0.007727603893727064\n",
      "32 200 loss: 0.01623338833451271\n",
      "32 300 loss: 0.022281765937805176\n",
      "32 acc: 0.7802\n",
      "33 0 loss: 0.0638335645198822\n",
      "33 100 loss: 0.003393852850422263\n",
      "33 200 loss: 0.021813908591866493\n",
      "33 300 loss: 0.0017301716143265367\n",
      "33 acc: 0.7787\n",
      "34 0 loss: 0.01239284873008728\n",
      "34 100 loss: 0.01160876452922821\n",
      "34 200 loss: 0.015311457216739655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 300 loss: 0.016188522800803185\n",
      "34 acc: 0.7927\n",
      "35 0 loss: 0.035414427518844604\n",
      "35 100 loss: 0.005169284529983997\n",
      "35 200 loss: 0.03917956352233887\n",
      "35 300 loss: 0.07831674814224243\n",
      "35 acc: 0.769\n",
      "36 0 loss: 0.11004476994276047\n",
      "36 100 loss: 0.020114250481128693\n",
      "36 200 loss: 0.014497073367238045\n",
      "36 300 loss: 0.016592402011156082\n",
      "36 acc: 0.7856\n",
      "37 0 loss: 0.01985328458249569\n",
      "37 100 loss: 0.035519760102033615\n",
      "37 200 loss: 0.01739606074988842\n",
      "37 300 loss: 0.08349385857582092\n",
      "37 acc: 0.7835\n",
      "38 0 loss: 0.025591056793928146\n",
      "38 100 loss: 0.03531862422823906\n",
      "38 200 loss: 0.03286343812942505\n",
      "38 300 loss: 0.017787469550967216\n",
      "38 acc: 0.7834\n",
      "39 0 loss: 0.04077257588505745\n",
      "39 100 loss: 0.049417734146118164\n",
      "39 200 loss: 0.0229530967772007\n",
      "39 300 loss: 0.11351926624774933\n",
      "39 acc: 0.7828\n",
      "40 0 loss: 0.034577928483486176\n",
      "40 100 loss: 0.009121810086071491\n",
      "40 200 loss: 0.009624643251299858\n",
      "40 300 loss: 0.0013881982304155827\n",
      "40 acc: 0.7809\n",
      "41 0 loss: 0.012288021855056286\n",
      "41 100 loss: 0.01648898236453533\n",
      "41 200 loss: 0.00781268160790205\n",
      "41 300 loss: 0.017626311630010605\n",
      "41 acc: 0.789\n",
      "42 0 loss: 0.006115554831922054\n",
      "42 100 loss: 0.01526124868541956\n",
      "42 200 loss: 0.007569963112473488\n",
      "42 300 loss: 0.018155716359615326\n",
      "42 acc: 0.7893\n",
      "43 0 loss: 0.034705132246017456\n",
      "43 100 loss: 0.03024175390601158\n",
      "43 200 loss: 0.061963096261024475\n",
      "43 300 loss: 0.07893483340740204\n",
      "43 acc: 0.7839\n",
      "44 0 loss: 0.011803654953837395\n",
      "44 100 loss: 0.03440868854522705\n",
      "44 200 loss: 0.00014768012624699622\n",
      "44 300 loss: 0.03805937618017197\n",
      "44 acc: 0.7865\n",
      "45 0 loss: 0.009027447551488876\n",
      "45 100 loss: 0.025731610134243965\n",
      "45 200 loss: 0.007044993806630373\n",
      "45 300 loss: 0.041116807609796524\n",
      "45 acc: 0.7853\n",
      "46 0 loss: 0.0070951865054667\n",
      "46 100 loss: 0.020215041935443878\n",
      "46 200 loss: 0.0005736408056691289\n",
      "46 300 loss: 0.005814759526401758\n",
      "46 acc: 0.7832\n",
      "47 0 loss: 0.0041669211350381374\n",
      "47 100 loss: 0.009891072288155556\n",
      "47 200 loss: 0.018812524154782295\n",
      "47 300 loss: 0.02301127091050148\n",
      "47 acc: 0.7707\n",
      "48 0 loss: 0.03622924163937569\n",
      "48 100 loss: 0.011745757423341274\n",
      "48 200 loss: 0.00850679725408554\n",
      "48 300 loss: 0.0013113688910380006\n",
      "48 acc: 0.7844\n",
      "49 0 loss: 0.003022447694092989\n",
      "49 100 loss: 0.007237450685352087\n",
      "49 200 loss: 0.0032028856221586466\n",
      "49 300 loss: 0.011226971633732319\n",
      "49 acc: 0.78\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import layers, optimizers, datasets, Sequential\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "conv_layers = [ # 5 units of conv + max pooling\n",
    "    # unit 1\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 2\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 3\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 4\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 5\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255.-1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "(x,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print('sample:', sample[0].shape, sample[1].shape,\n",
    "      tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "    conv_net = Sequential(conv_layers)\n",
    "\n",
    "    fc_net = Sequential([\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(10, activation=None),\n",
    "    ])\n",
    "\n",
    "    conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "    fc_net.build(input_shape=[None, 512])\n",
    "    conv_net.summary()\n",
    "    fc_net.summary()\n",
    "    optimizer = optimizers.Adam(lr=1e-4)\n",
    "\n",
    "    # [1, 2] + [3, 4] => [1, 2, 3, 4]\n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "\n",
    "    for epoch in range(50):\n",
    "\n",
    "        for step, (x,y) in enumerate(train_db):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "                out = conv_net(x)\n",
    "                # flatten, => [b, 512]\n",
    "                out = tf.reshape(out, [-1, 512])\n",
    "                # [b, 512] => [b, 10]\n",
    "                logits = fc_net(out)\n",
    "                # [b] => [b, 10]\n",
    "                y_onehot = tf.one_hot(y, depth=10)\n",
    "                # compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "            if step %100 == 0:\n",
    "                print(epoch, step, 'loss:', float(loss))\n",
    "\n",
    "\n",
    "\n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for x,y in test_db:\n",
    "\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            logits = fc_net(out)\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "            correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "\n",
    "            total_num += x.shape[0]\n",
    "            total_correct += int(correct)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, 'acc:', acc)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
