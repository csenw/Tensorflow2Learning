{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200315\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "    def _map_fn(img):\n",
    "        # this function mainly resize the image and scale into -1 and 1\n",
    "        img = tf.image.resize(img,[resize, resize])\n",
    "        img = tf.clip_by_value(img, 0,255)\n",
    "        img = img /127.5 - 1\n",
    "        return img\n",
    "    \n",
    "    dataset = disk_image_batch_dataset(img_paths, \n",
    "                                       batch_size, \n",
    "                                       drop_remainder=drop_remainder, \n",
    "                                       map_fn = _map_fn, \n",
    "                                       shuffle=shuffle, \n",
    "                                       repeat = repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    # the number of img_paths is the number of images, len_dataset is the floor of #img / #batch_size\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "    \n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "def batch_dataset(dataset,\n",
    "                 batch_size,\n",
    "                 drop_remainder=True,\n",
    "                 n_prefetch_batch=1,\n",
    "                 filter_fn=None,\n",
    "                 map_fn=None,\n",
    "                 n_map_threads=None,\n",
    "                 filter_after_map=False,\n",
    "                 shuffle=True,\n",
    "                 shuffle_buffer_size=None,\n",
    "                 repeat=None):\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size*128, 2048)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "        \n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "            \n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls = n_map_threads)\n",
    "    else:\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls = n_map_threads)\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "            \n",
    "    dataset = dataset.batch(batch_size, drop_remainder = drop_remainder)\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "    \n",
    "    return dataset\n",
    "# some methods of datasets\n",
    "# batch(batch_size, drop_remainder=False) combines consecutive elements of this dataset into batches\n",
    "#    e.g. dataset: 1, 2, 3, 4, 5, 6, 7, 8 batch_size=2: (1,2,3),(4,5,6),(7,8)\n",
    "# shuffle(buffer_size, seed=None, reshuffle_each_iteration=None) Randomly shuffles the elements of this dataset.\n",
    "# filter(predicate) filters this dataset according to predicate. predicate: A function mapping a dataset element to a boolean.\n",
    "# repeat(count=None): Repeats this dataset so each original value is seen count times.\n",
    "#    e.g. (1,2,3): repeat(3) -> (1,2,3,1,2,3,1,2,3)\n",
    "# prefetch(buffer_size): Creates a Dataset that prefetches elements from this dataset.\n",
    "# prefetch is a mechanism to improve latency and througput. \n",
    "#     e.g. dataset.prefetch(2): two samples are prefetched\n",
    "#     e.g. dataset.batch(32).prefecth(2): two batches are prefetched\n",
    "\n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                             batch_size,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                           batch_size,\n",
    "                           drop_remainder,\n",
    "                           filter_fn,\n",
    "                           map_fn,\n",
    "                           n_map_threads,\n",
    "                           filter_after_map,\n",
    "                           shuffle,\n",
    "                           shuffle_buffer_size,\n",
    "                           repeat)\n",
    "    return dataset\n",
    "\n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else: \n",
    "        memory_data = (img_paths, labels)\n",
    "        \n",
    "    def parse_fn(path, *labels):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        return (img,) + label\n",
    "    \n",
    "    if map_fn:\n",
    "        def map_fn(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "    \n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.00333924]\n",
      " [ 0.00041265]], shape=(2, 1), dtype=float32)\n",
      "(2, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        filter = 64\n",
    "        \n",
    "        self.conv1 = layers.Conv2DTranspose(filter*8, 4, 1, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = layers.Conv2DTranspose(filter*4, 4, 2, 'same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv3 = layers.Conv2DTranspose(filter*2, 4, 2, 'same', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = layers.Conv2DTranspose(filter*1, 4, 2, 'same', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = layers.Conv2DTranspose(3, 4,2, 'same', use_bias=False)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = tf.reshape(x, (x.shape[0], 1, 1, x.shape[1]))\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = tf.nn.relu(self.bn1(self.conv1(x), training = training))\n",
    "        x = tf.nn.relu(self.bn2(self.conv2(x), training = training))\n",
    "        x = tf.nn.relu(self.bn3(self.conv3(x), training = training))\n",
    "        x = tf.nn.relu(self.bn4(self.conv4(x), training = training))\n",
    "        x = self.conv5(x)\n",
    "        x = tf.tanh(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        filter = 64\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(filter, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(filter*2, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(filter*4, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(filter*8, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(filter*16, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        \n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.fc = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training= training))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "def main():\n",
    "    \n",
    "    d = Discriminator()\n",
    "    g = Generator()\n",
    "    \n",
    "    x = tf.random.normal([2, 64, 64, 3])\n",
    "    z = tf.random.normal([2, 100])\n",
    "    \n",
    "    prob = d(x)\n",
    "    print(prob)\n",
    "    \n",
    "    x_hat = g(z)\n",
    "    print(x_hat.shape)\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00787218]\n",
      " [0.02203691]], shape=(2, 1), dtype=float32)\n",
      "(2, 64, 64, 3)\n",
      "image num: 51223\n",
      "<PrefetchDataset shapes: (64, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(64, 64, 64, 3) 1.0 -1.0\n",
      "0 d-loss: 1.0144507884979248 g-loss: 0.6073201298713684\n",
      "100 d-loss: 0.1931481510400772 g-loss: 0.4116968512535095\n",
      "200 d-loss: 0.12361609935760498 g-loss: 0.5932700634002686\n",
      "300 d-loss: 0.19069337844848633 g-loss: 1.1832389831542969\n",
      "400 d-loss: 0.13474829494953156 g-loss: 1.4560717344284058\n",
      "500 d-loss: 0.18069937825202942 g-loss: 1.2682995796203613\n",
      "600 d-loss: 0.07482534646987915 g-loss: 2.2602500915527344\n",
      "700 d-loss: 0.05899122357368469 g-loss: 2.4632179737091064\n",
      "800 d-loss: 0.030031336471438408 g-loss: 1.0808496475219727\n",
      "900 d-loss: 0.07166185230016708 g-loss: 1.3660860061645508\n",
      "1000 d-loss: 0.07767441868782043 g-loss: 1.9403941631317139\n",
      "1100 d-loss: 0.18762856721878052 g-loss: 1.6505281925201416\n",
      "1200 d-loss: 0.04866134375333786 g-loss: 1.535111427307129\n",
      "1300 d-loss: 0.07233203202486038 g-loss: 2.235523223876953\n",
      "1400 d-loss: 0.007182661443948746 g-loss: 2.237419605255127\n",
      "1500 d-loss: 0.07420441508293152 g-loss: 2.051640510559082\n",
      "1600 d-loss: 0.048315342515707016 g-loss: 2.5042529106140137\n",
      "1700 d-loss: 0.09913460910320282 g-loss: 2.009244441986084\n",
      "1800 d-loss: 0.01227172277867794 g-loss: 2.4288253784179688\n",
      "1900 d-loss: 0.03519849106669426 g-loss: 2.0805230140686035\n",
      "2000 d-loss: 0.0022310519125312567 g-loss: 2.5145068168640137\n",
      "2100 d-loss: 0.027338793501257896 g-loss: 2.613062620162964\n",
      "2200 d-loss: 0.004392934963107109 g-loss: 2.509085178375244\n",
      "2300 d-loss: 0.004079204984009266 g-loss: 2.6406564712524414\n",
      "2400 d-loss: 0.01090307254344225 g-loss: 3.064279556274414\n",
      "2500 d-loss: 0.001383814844302833 g-loss: 2.1767520904541016\n",
      "2600 d-loss: 0.01153615117073059 g-loss: 2.5829224586486816\n",
      "2700 d-loss: 0.006126112304627895 g-loss: 2.232692003250122\n",
      "2800 d-loss: 0.0013868003152310848 g-loss: 2.1313557624816895\n",
      "2900 d-loss: 0.011156135238707066 g-loss: 2.8363518714904785\n",
      "3000 d-loss: 0.01049166638404131 g-loss: 2.894850254058838\n",
      "3100 d-loss: 0.01616624929010868 g-loss: 2.5370874404907227\n",
      "3200 d-loss: 0.013771116733551025 g-loss: 3.1724889278411865\n",
      "3300 d-loss: 0.020386235788464546 g-loss: 2.4196150302886963\n",
      "3400 d-loss: 0.017697876319289207 g-loss: 2.482948064804077\n",
      "3500 d-loss: 0.011413224041461945 g-loss: 2.004598617553711\n",
      "3600 d-loss: 0.0037682338152080774 g-loss: 0.7027831077575684\n",
      "3700 d-loss: 0.02369406819343567 g-loss: 2.3681092262268066\n",
      "3800 d-loss: 0.008828368969261646 g-loss: 1.786683201789856\n",
      "3900 d-loss: 0.020130692049860954 g-loss: 1.2904456853866577\n",
      "4000 d-loss: 0.006237077992409468 g-loss: 2.0986106395721436\n",
      "4100 d-loss: 0.0010795878479257226 g-loss: 0.6577427387237549\n",
      "4200 d-loss: 0.00968415942043066 g-loss: 0.6522470712661743\n",
      "4300 d-loss: 0.0016307472251355648 g-loss: 0.8063498735427856\n",
      "4400 d-loss: 0.002395560732111335 g-loss: 1.1420204639434814\n",
      "4500 d-loss: 0.008564137853682041 g-loss: 1.8662770986557007\n",
      "4600 d-loss: 0.008464054204523563 g-loss: 0.7360314130783081\n",
      "4700 d-loss: 0.04960790276527405 g-loss: 0.8584680557250977\n",
      "4800 d-loss: 0.02003530226647854 g-loss: 0.9032557606697083\n",
      "4900 d-loss: 0.004540503025054932 g-loss: 0.5330663919448853\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from scipy.misc import toimage\n",
    "from PIL import Image\n",
    "import glob\n",
    "import multiprocessing\n",
    "\n",
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "\n",
    "    # @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        # img = tf.image.random_crop(img,[resize, resize])\n",
    "        # img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1 #-1~1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "\n",
    "def batch_dataset(dataset,\n",
    "                  batch_size,\n",
    "                  drop_remainder=True,\n",
    "                  n_prefetch_batch=1,\n",
    "                  filter_fn=None,\n",
    "                  map_fn=None,\n",
    "                  n_map_threads=None,\n",
    "                  filter_after_map=False,\n",
    "                  shuffle=True,\n",
    "                  shuffle_buffer_size=None,\n",
    "                  repeat=None):\n",
    "    # set defaults\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n",
    "\n",
    "    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "    else:  # [*] this is slower\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                              batch_size,\n",
    "                              drop_remainder=True,\n",
    "                              n_prefetch_batch=1,\n",
    "                              filter_fn=None,\n",
    "                              map_fn=None,\n",
    "                              n_map_threads=None,\n",
    "                              filter_after_map=False,\n",
    "                              shuffle=True,\n",
    "                              shuffle_buffer_size=None,\n",
    "                              repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                            batch_size,\n",
    "                            drop_remainder=drop_remainder,\n",
    "                            n_prefetch_batch=n_prefetch_batch,\n",
    "                            filter_fn=filter_fn,\n",
    "                            map_fn=map_fn,\n",
    "                            n_map_threads=n_map_threads,\n",
    "                            filter_after_map=filter_after_map,\n",
    "                            shuffle=shuffle,\n",
    "                            shuffle_buffer_size=shuffle_buffer_size,\n",
    "                            repeat=repeat)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else:\n",
    "        memory_data = (img_paths, labels)\n",
    "\n",
    "    def parse_fn(path, *label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # fix channels to 3\n",
    "        return (img,) + label\n",
    "\n",
    "    if map_fn:  # fuse `map_fn` and `parse_fn`\n",
    "        def map_fn_(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "\n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "\n",
    "    return dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        filter = 64\n",
    "        \n",
    "        self.conv1 = layers.Conv2DTranspose(filter*8, 4, 1, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = layers.Conv2DTranspose(filter*4, 4, 2, 'same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv3 = layers.Conv2DTranspose(filter*2, 4, 2, 'same', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = layers.Conv2DTranspose(filter*1, 4, 2, 'same', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = layers.Conv2DTranspose(3, 4,2, 'same', use_bias=False)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = tf.reshape(x, (x.shape[0], 1, 1, x.shape[1]))\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = tf.nn.relu(self.bn1(self.conv1(x), training = training))\n",
    "        x = tf.nn.relu(self.bn2(self.conv2(x), training = training))\n",
    "        x = tf.nn.relu(self.bn3(self.conv3(x), training = training))\n",
    "        x = tf.nn.relu(self.bn4(self.conv4(x), training = training))\n",
    "        x = self.conv5(x)\n",
    "        x = tf.tanh(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        filter = 64\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(filter, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(filter*2, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(filter*4, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(filter*8, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(filter*16, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        \n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.fc = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training= training))\n",
    "        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training= training))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "def main():\n",
    "    \n",
    "    d = Discriminator()\n",
    "    g = Generator()\n",
    "    \n",
    "    x = tf.random.normal([2, 64, 64, 3])\n",
    "    z = tf.random.normal([2, 100])\n",
    "    \n",
    "    prob = d(x)\n",
    "    print(prob)\n",
    "    \n",
    "    x_hat = g(z)\n",
    "    print(x_hat.shape)\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    \n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img) + 1.0 * 127.5).astype(np.uint8)\n",
    "        return img\n",
    "    \n",
    "    preprocessed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocessed[b, :, :, :]\n",
    "        else:\n",
    "            single_row=np.concatenate((single_row, preprocessed[b, :, :, :]), axis=1)\n",
    "        \n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)\n",
    "\n",
    "def celoss_ones(logits):\n",
    "    y = tf.ones_like(logits)\n",
    "    loss = keras.losses.binary_crossentropy(y, logits, from_logits = True)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def celoss_zeros(logits):\n",
    "    y = tf.zeros_like(logits)\n",
    "    loss = keras.losses.binary_crossentropy(y, logits, from_logits = True)\n",
    "    return tf.reduce_min(loss)\n",
    "\n",
    "# Loss function for Discriminator\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    \n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    \n",
    "    return d_loss_fake + d_loss_real\n",
    "\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    return celoss_ones(d_fake_logits)\n",
    "    \n",
    "def main():\n",
    "    tf.random.set_seed(3333)\n",
    "    np.random.seed(3333)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    assert tf.__version__.startswith('2.')\n",
    "    \n",
    "    z_dim = 100 # dimensionality of latent variable\n",
    "    epochs = 3000000\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.0002\n",
    "    is_training = True\n",
    "    \n",
    "    img_path = glob.glob('./faces/*.jpg')\n",
    "    print('image num:', len(img_path))\n",
    "    \n",
    "    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=64)\n",
    "    print(dataset, img_shape)\n",
    "    \n",
    "    sample = next(iter(dataset))\n",
    "    print(sample.shape, tf.reduce_max(sample).numpy(), tf.reduce_min(sample).numpy())\n",
    "    dataset = dataset.repeat(100)\n",
    "    db_iter = iter(dataset)\n",
    "    \n",
    "    generator = Generator()\n",
    "    # why input shape is 4,z_dim?\n",
    "    generator.build(input_shape = (4, z_dim))\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.build(input_shape = (4, 64, 64, 3))\n",
    "    \n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.5)\n",
    "    \n",
    "    #generator.load_weights('generator.ckpt')\n",
    "    #discriminator.load_weights('discriminator.ckpt')\n",
    "    #print('Loaded ckpt!!')\n",
    "    \n",
    "    d_losses, g_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # train discriminator ONE step\n",
    "        for _ in range(1):\n",
    "            # randomly generate a noise batch : 64*100\n",
    "            batch_z = tf.random.normal([batch_size, z_dim])\n",
    "            batch_x = next(db_iter)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "        \n",
    "        # train generator One step\n",
    "        batch_z = tf.random.normal([batch_size, z_dim])\n",
    "        batch_x = next(db_iter)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, 'd-loss:', float(d_loss), 'g-loss:', float(g_loss))\n",
    "            z = tf.random.normal([100, z_dim])\n",
    "            fake_image = generator(z, training =False)\n",
    "            img_path = os.path.join('./faces/gan_images', 'gan-%d.png'%epoch)\n",
    "            save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "            \n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "            \n",
    "            if epoch %10000 == 1:\n",
    "                generator.save_weights('generator.ckpt')\n",
    "                discriminator.save_weights('discriminator.ckpt')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images num: 51223\n",
      "<PrefetchDataset shapes: (64, 64, 64, 3), types: tf.float32> (64, 64, 3)\n",
      "(64, 64, 64, 3) 1.0 -1.0\n",
      "0 d-loss: 1.4971634149551392 g-loss: 0.547619640827179\n",
      "./faces/gan_images/gan-0.png\n",
      "100 d-loss: 0.6125951409339905 g-loss: 1.462670087814331\n",
      "./faces/gan_images/gan-100.png\n",
      "200 d-loss: 0.42342060804367065 g-loss: 2.2695488929748535\n",
      "./faces/gan_images/gan-200.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-dba3a591f3d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-dba3a591f3d5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# 生成器前向计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-dba3a591f3d5>\u001b[0m in \u001b[0;36mg_loss_fn\u001b[0;34m(generator, discriminator, batch_z, is_training)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0mfake_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# 在训练生成网络时，需要迫使生成图片判定为真\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0md_fake_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;31m# 计算生成图片与1之间的误差\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceloss_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    966\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-dba3a591f3d5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# 卷积-BN-激活函数:(4, 1024)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;31m# 打平\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m           'The first argument to `Layer.call` must always be passed.')\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m     \u001b[0mcall_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import  os,multiprocessing\n",
    "import  numpy as np\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import  glob\n",
    "\n",
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "\n",
    "    # @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        # img = tf.image.random_crop(img,[resize, resize])\n",
    "        # img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1 #-1~1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "\n",
    "def batch_dataset(dataset,\n",
    "                  batch_size,\n",
    "                  drop_remainder=True,\n",
    "                  n_prefetch_batch=1,\n",
    "                  filter_fn=None,\n",
    "                  map_fn=None,\n",
    "                  n_map_threads=None,\n",
    "                  filter_after_map=False,\n",
    "                  shuffle=True,\n",
    "                  shuffle_buffer_size=None,\n",
    "                  repeat=None):\n",
    "    # set defaults\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n",
    "\n",
    "    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "    else:  # [*] this is slower\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                              batch_size,\n",
    "                              drop_remainder=True,\n",
    "                              n_prefetch_batch=1,\n",
    "                              filter_fn=None,\n",
    "                              map_fn=None,\n",
    "                              n_map_threads=None,\n",
    "                              filter_after_map=False,\n",
    "                              shuffle=True,\n",
    "                              shuffle_buffer_size=None,\n",
    "                              repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                            batch_size,\n",
    "                            drop_remainder=drop_remainder,\n",
    "                            n_prefetch_batch=n_prefetch_batch,\n",
    "                            filter_fn=filter_fn,\n",
    "                            map_fn=map_fn,\n",
    "                            n_map_threads=n_map_threads,\n",
    "                            filter_after_map=filter_after_map,\n",
    "                            shuffle=shuffle,\n",
    "                            shuffle_buffer_size=shuffle_buffer_size,\n",
    "                            repeat=repeat)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else:\n",
    "        memory_data = (img_paths, labels)\n",
    "\n",
    "    def parse_fn(path, *label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # fix channels to 3\n",
    "        return (img,) + label\n",
    "\n",
    "    if map_fn:  # fuse `map_fn` and `parse_fn`\n",
    "        def map_fn_(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "\n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class Generator(keras.Model):\n",
    "    # 生成器网络\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        filter = 64\n",
    "        # 转置卷积层1,输出channel为filter*8,核大小4,步长1,不使用padding,不使用偏置\n",
    "        self.conv1 = layers.Conv2DTranspose(filter*8, 4,1, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # 转置卷积层2\n",
    "        self.conv2 = layers.Conv2DTranspose(filter*4, 4,2, 'same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # 转置卷积层3\n",
    "        self.conv3 = layers.Conv2DTranspose(filter*2, 4,2, 'same', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        # 转置卷积层4\n",
    "        self.conv4 = layers.Conv2DTranspose(filter*1, 4,2, 'same', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        # 转置卷积层5\n",
    "        self.conv5 = layers.Conv2DTranspose(3, 4,2, 'same', use_bias=False)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs # [z, 100]\n",
    "        # Reshape乘4D张量，方便后续转置卷积运算:(b, 1, 1, 100)\n",
    "        x = tf.reshape(x, (x.shape[0], 1, 1, x.shape[1]))\n",
    "        x = tf.nn.relu(x) # 激活函数\n",
    "        # 转置卷积-BN-激活函数:(b, 4, 4, 512)\n",
    "        x = tf.nn.relu(self.bn1(self.conv1(x), training=training))\n",
    "        # 转置卷积-BN-激活函数:(b, 8, 8, 256)\n",
    "        x = tf.nn.relu(self.bn2(self.conv2(x), training=training))\n",
    "        # 转置卷积-BN-激活函数:(b, 16, 16, 128)\n",
    "        x = tf.nn.relu(self.bn3(self.conv3(x), training=training))\n",
    "        # 转置卷积-BN-激活函数:(b, 32, 32, 64)\n",
    "        x = tf.nn.relu(self.bn4(self.conv4(x), training=training))\n",
    "        # 转置卷积-激活函数:(b, 64, 64, 3)\n",
    "        x = self.conv5(x)\n",
    "        x = tf.tanh(x) # 输出x范围-1~1,与预处理一致\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    # 判别器\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        filter = 64\n",
    "        # 卷积层\n",
    "        self.conv1 = layers.Conv2D(filter, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # 卷积层\n",
    "        self.conv2 = layers.Conv2D(filter*2, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # 卷积层\n",
    "        self.conv3 = layers.Conv2D(filter*4, 4, 2, 'valid', use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        # 卷积层\n",
    "        self.conv4 = layers.Conv2D(filter*8, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        # 卷积层\n",
    "        self.conv5 = layers.Conv2D(filter*16, 3, 1, 'valid', use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        # 全局池化层\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        # 特征打平\n",
    "        self.flatten = layers.Flatten()\n",
    "        # 2分类全连接层\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # 卷积-BN-激活函数:(4, 31, 31, 64)\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(inputs), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 14, 14, 128)\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 6, 6, 256)\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 4, 4, 512)\n",
    "        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 2, 2, 1024)\n",
    "        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training=training))\n",
    "        # 卷积-BN-激活函数:(4, 1024)\n",
    "        x = self.pool(x)\n",
    "        # 打平\n",
    "        x = self.flatten(x)\n",
    "        # 输出，[b, 1024] => [b, 1]\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    #toimage(final_image).save(image_path)\n",
    "    #print(image_path)\n",
    "    Image.fromarray(final_image).save(image_path)\n",
    "\n",
    "\n",
    "def celoss_ones(logits):\n",
    "    # 计算属于与标签为1的交叉熵\n",
    "    y = tf.ones_like(logits)\n",
    "    loss = keras.losses.binary_crossentropy(y, logits, from_logits=True)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def celoss_zeros(logits):\n",
    "    # 计算属于与便签为0的交叉熵\n",
    "    y = tf.zeros_like(logits)\n",
    "    loss = keras.losses.binary_crossentropy(y, logits, from_logits=True)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 计算判别器的误差函数\n",
    "    # 采样生成图片\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    # 判定生成图片\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    # 判定真实图片\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    # 真实图片与1之间的误差\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    # 生成图片与0之间的误差\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    # 合并误差\n",
    "    loss = d_loss_fake + d_loss_real\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    # 采样生成图片\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    # 在训练生成网络时，需要迫使生成图片判定为真\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    # 计算生成图片与1之间的误差\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def main():\n",
    "\n",
    "    tf.random.set_seed(3333)\n",
    "    np.random.seed(3333)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    assert tf.__version__.startswith('2.')\n",
    "\n",
    "\n",
    "    z_dim = 100 # 隐藏向量z的长度\n",
    "    epochs = 3000000 # 训练步数\n",
    "    batch_size = 64 # batch size\n",
    "    learning_rate = 0.0002\n",
    "    is_training = True\n",
    "\n",
    "    # 获取数据集路径\n",
    "    # C:\\Users\\z390\\Downloads\\anime-faces\n",
    "    # r'C:\\Users\\z390\\Downloads\\faces\\*.jpg'\n",
    "    img_path = glob.glob('./faces/*.jpg')\n",
    "    # img_path = glob.glob(r'C:\\Users\\z390\\Downloads\\getchu_aligned_with_label\\GetChu_aligned2\\*.jpg')\n",
    "    # img_path.extend(img_path2)\n",
    "    print('images num:', len(img_path))\n",
    "    # 构建数据集对象\n",
    "    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=64)\n",
    "    print(dataset, img_shape)\n",
    "    sample = next(iter(dataset)) # 采样\n",
    "    print(sample.shape, tf.reduce_max(sample).numpy(),\n",
    "          tf.reduce_min(sample).numpy())\n",
    "    dataset = dataset.repeat(100) # 重复循环\n",
    "    db_iter = iter(dataset)\n",
    "\n",
    "\n",
    "    generator = Generator() # 创建生成器\n",
    "    generator.build(input_shape = (4, z_dim))\n",
    "    discriminator = Discriminator() # 创建判别器\n",
    "    discriminator.build(input_shape=(4, 64, 64, 3))\n",
    "    # 分别为生成器和判别器创建优化器\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "\n",
    "    #generator.load_weights('generator.ckpt')\n",
    "    #discriminator.load_weights('discriminator.ckpt')\n",
    "    #print('Loaded chpt!!')\n",
    "\n",
    "    d_losses, g_losses = [],[]\n",
    "    for epoch in range(epochs): # 训练epochs次\n",
    "        # 1. 训练判别器\n",
    "        for _ in range(1):\n",
    "            # 采样隐藏向量\n",
    "            batch_z = tf.random.normal([batch_size, z_dim])\n",
    "            batch_x = next(db_iter) # 采样真实图片\n",
    "            # 判别器前向计算\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "        # 2. 训练生成器\n",
    "        # 采样隐藏向量\n",
    "        batch_z = tf.random.normal([batch_size, z_dim])\n",
    "        batch_x = next(db_iter) # 采样真实图片\n",
    "        # 生成器前向计算\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, 'd-loss:',float(d_loss), 'g-loss:', float(g_loss))\n",
    "            # 可视化\n",
    "            z = tf.random.normal([100, z_dim])\n",
    "            fake_image = generator(z, training=False)\n",
    "            img_path = os.path.join('./faces/gan_images', 'gan-%d.png'%epoch)\n",
    "            save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "\n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "\n",
    "            if epoch % 10000 == 1:\n",
    "                # print(d_losses)\n",
    "                # print(g_losses)\n",
    "                generator.save_weights('generator.ckpt')\n",
    "                discriminator.save_weights('discriminator.ckpt')\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
